import os
import hashlib

def file_hash(path, chunk_size=8192):
    """Return SHA256 hash of a file."""
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(chunk_size), b""):
            h.update(chunk)
    return h.hexdigest()

seen = {}
duplicates = []

for root, _, files in os.walk("."):
    if ".git" in root or ".github" in root:
        continue  # skip metadata folders
    for file in files:
        filepath = os.path.join(root, file)
        hash_val = file_hash(filepath)
        if hash_val in seen:
            duplicates.append(filepath)
        else:
            seen[hash_val] = filepath

# Report file
report_path = ".github/scripts/duplicates_report.txt"
with open(report_path, "w") as report:
    if duplicates:
        report.write("### ðŸš¨ Duplicate Files Removed\n")
        for dup in duplicates:
            report.write(f"- {dup}\n")
    else:
        report.write("âœ… No duplicate files found.\n")

# Delete duplicates
for dup in duplicates:
    print(f"Removing duplicate: {dup}")
    os.remove(dup)

if not duplicates:
    print("No duplicates found.")